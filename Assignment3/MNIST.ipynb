{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "%matplotlib inline\n",
    "\n",
    "# Check CUDA\n",
    "cuda = torch.cuda.is_available()\n",
    "print('GPU:', cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "LATENT_DIM = 2\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "Train_Data = MNIST(root='../Assignment3_dataset/MNIST', train=True, transform=transforms.ToTensor(), download=True)\n",
    "Train_DataLoader = data.DataLoader(dataset=Train_Data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if not os.path.exists(\"../Assignment3/params\"):\n",
    "    os.mkdir(\"../Assignment3/params\")\n",
    "if not os.path.exists(\"../Assignment3/img\"):\n",
    "    os.mkdir(\"../Assignment3/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-Encoder\n",
    "\n",
    "class AutoEncoderModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Conv\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "        )  # N,3,14,14\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 3, 2, 1),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "        )  # N,6,7,7\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(6 * 7 * 7, 128),\n",
    "        )  # N,128\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(128, 6 * 7 * 7),\n",
    "            nn.BatchNorm1d(6 * 7 * 7),\n",
    "            nn.ReLU()\n",
    "        )  # 7,7\n",
    "\n",
    "        # DeConv\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(6, 3, 3, 2, 1, output_padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU()\n",
    "        )  # 14,14\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(3, 1, 3, 2, 1, output_padding=1),\n",
    "            nn.ReLU()\n",
    "        )  # 28.28\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = torch.reshape(x2, [x2.size(0), -1])\n",
    "        code = self.fc1(x2)\n",
    "\n",
    "        # Decoder\n",
    "        y1 = self.fc2(code)\n",
    "        y1 = torch.reshape(y1, [y1.size(0), 6, 7, 7])\n",
    "        y2 = self.conv3(y1)\n",
    "        out = self.conv4(y2)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "def Train(self):\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(EPOCHS):\n",
    "        for step, (x, y) in enumerate(Train_DataLoader):\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            output = self(x)\n",
    "            loss = criterion(output, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print('Epoch:', epoch, '|Step:', step, '|train loss:%.4f' % loss.cpu().data.numpy())\n",
    "        # Save model\n",
    "        torch.save(self.state_dict(), '../Assignment3/params/ae_params.pkl')\n",
    "        # Print Last Image\n",
    "        save_image(output.cpu().data[:64], '../Assignment3/img/ae_img.png', nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\VScode WorkStation\\Neural-Network---Deep-Learning\\Assignment3\\MNIST.ipynb 单元格 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VScode%20WorkStation/Neural-Network---Deep-Learning/Assignment3/MNIST.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m AutoEncoderModel()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VScode%20WorkStation/Neural-Network---Deep-Learning/Assignment3/MNIST.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m cuda:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/VScode%20WorkStation/Neural-Network---Deep-Learning/Assignment3/MNIST.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VScode%20WorkStation/Neural-Network---Deep-Learning/Assignment3/MNIST.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m Train(model)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    889\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \n\u001b[0;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    889\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \n\u001b[0;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = AutoEncoderModel()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "Train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
