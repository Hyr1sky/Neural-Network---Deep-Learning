# ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒä½œä¸šï¼ˆä¸‰ï¼‰
# å®éªŒå†…å®¹ï¼šæ·±åº¦è‡ªç¼–ç å™¨
---
ä½•å°‰å® 2021213599

## å®éªŒä¸€ï¼š åŸºäºMNISTçš„AE
### å®éªŒè¦æ±‚ï¼š

- å®Œæˆæ•°æ®è¯»å†™å¹¶è¯•ç€æ­å»ºæ·±åº¦è‡ªç¼–ç å™¨ç½‘ç»œ 
- é€‰æ‹©äºŒå…ƒäº¤å‰ç†µå‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œåœ¨é™åˆ¶bottleneckå±‚ç»´åº¦ä¸º2çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹
- è®¾ç½®å™ªå£°å› å­ä¸º0.4ï¼Œåœ¨è¾“å…¥å›¾åƒä¸Šå åŠ å‡å€¼ä¸º0ä¸”æ–¹å·®ä¸º1çš„æ ‡å‡†é«˜æ–¯ç™½å™ªå£°ï¼Œè®­ç»ƒé™å™ªè‡ªç¼–ç å™¨ï¼Œå¹¶è¿›è¡Œé™å™ªç»“æœå±•ç¤º  
- è¯•åœ¨é—®é¢˜(2)çš„åŸºç¡€ä¸Šï¼Œå¯¹latent codeè¿›è¡Œå‡åŒ€é‡‡æ ·ï¼Œå¹¶åˆ©ç”¨è§£ç å™¨å¯¹é‡‡æ ·ç»“æœè¿›è¡Œæ¢å¤ï¼Œè§‚å¯Ÿå¹¶æè¿°æ‰€å¾—åˆ°çš„ç»“æœ
- è¯•åœ¨é—®é¢˜(4)çš„åŸºç¡€ä¸Šï¼Œåœ¨è®­ç»ƒæ·±åº¦è‡ªç¼–ç å™¨æ—¶ä½¿ç”¨ L2æ­£åˆ™åŒ–ï¼Œè§‚å¯Ÿå¹¶æè¿°ä½ æ‰€å¾—åˆ°çš„ç»“æœã€‚

---
### æ•™è®­ï¼š
ç›¸ä¿¡Andrew Ngçš„è¯ï¼Œ"When you try something new, do the dirty and quick staff first"
æ—©ä»MLPå¼€å§‹å†™ä¸å°±å¥½äº†ã€‚

---
### ææ–™ï¼š
1. [Anomaly Detection Using PyTorch Autoencoder and MNIST | by Benjamin | Medium](https://medium.com/@benjoe/anomaly-detection-using-pytorch-autoencoder-and-mnist-31c5c2186329)
2. [ä»€ä¹ˆæ˜¯æ·±åº¦ç”Ÿæˆæ¨¡å‹(Deep Generative Model)?)](https://www.zhihu.com/question/310388816/answer/2801712061)

---
### 1. æ•°æ®è¯»å†™ä¸AEç½‘ç»œ
#### 1.1 æ•°æ®è¯»å†™

`pytorch`é‡Œæœ‰MNISTï¼Œç›´æ¥æ­£å¸¸ä¸‹è½½å°±å¥½äº†

#### 1.2 ç½‘ç»œ

å‰åå†™äº†ä¸‰ç‰ˆï¼Œå› ä¸ºæœ€å¼€å§‹çš„CNNä¸å°½äººæ„ï¼Œä¿®æ”¹äº†å¾ˆä¹…ä¹‹åè¿˜æ˜¯æ•ˆæœå¾ˆå·®ï¼Œå°±æ¢æˆMLPä»ç®€å•å¼€å§‹ï¼Œç»“æœåè€Œæœ‰æ›´å¥½çš„æ”¶æ•ˆã€‚
æœ€åä¸€ç‰ˆç½‘ç»œçš„å±‚æ•°æœ€å°‘ï¼Œå¹¶ä¸”å‚è€ƒäº†æå®æ¯…è€å¸ˆè¯´çš„ç»´åº¦å…ˆå¢å†å‡ï¼Œè¾¾åˆ°äº†ä¸€ä¸ªæ¯”è¾ƒä¸é”™çš„æ•ˆæœã€‚

---
### 2. æ­£å¼è®­ç»ƒ(BCE/Bottleneck = 2)

**BCE**å¯ä»¥çœ‹ä½œæ˜¯æŠŠå›¾åƒç”Ÿæˆä½œä¸ºä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œ0/1åˆ†åˆ«ä»£è¡¨è¿™ä¸ªåƒç´ ç‚¹æ˜¯å¦éœ€è¦æ‰“ç‚¹ã€‚
_Loss function for binay inputs:_
$l(f(\mathbf{x}))=-\sum_k\left(x_k\log(\widehat{x}_k)+(1-x_k)\log(1-\widehat{x}_k)\right)$

æ¢å¤åçš„å›¾åƒï¼š
![[generative_images_9.png]]

---
### 3. Denoising-AE åŠ å™ªåè®­ç»ƒ

åŠ å…¥é«˜æ–¯å™ªå£°ï¼š
```python
	# add noise
    # x = self.add_noise(x)
Â  Â  noise_factor = 0.4
Â  Â  x = x + torch.normal(mean=0.0, std=1, size=x.size()) * noise_factor
```
å¯¹æ¯”å›¾ï¼š
![[great.png]]

åŠ å…¥å™ªå£°åå¯¹æŸå¤±å‡½æ•°çš„é€‰æ‹©éœ€è¦æ…é‡ï¼Œå®¹æ˜“å‡ºç°æ··æ‚çš„ç°è±¡ã€‚
**å¯¹äºæ¢å¤å›¾åƒè¾¹ç•Œä¸å¤Ÿæ¸…æ™°çš„é—®é¢˜ï¼Œå¯ä»¥å°è¯•åŠ å…¥è¾¹ç•Œç‰¹å¾æå–çš„`filter`å¯¹è¾¹ç•Œè¿›è¡Œé”åŒ–ï¼Œä½¿å¾—æ•°å­—æ›´åŠ æ¸…æ™°**

---
### 4. å‡åŒ€é‡‡æ ·åæ¢å¤

å®šä¹‰äº†`get_latent_code`å’Œ`generate_img`å‡½æ•°ï¼Œå¯¹éšè—å±‚è¿›è¡Œæå–ï¼Œè¿™é‡Œçš„é‡‡æ ·åæ¢å¤å›¾åƒçš„ä»£ç è¿˜å¯ä»¥è¿›ä¸€æ­¥å°è£…ï¼Œä½†æ˜¯å½“æ—¶ä¸ºäº†æ›´å¿«å‡ºç»“æœå°±æ²¡ä¿®æ”¹äº†ã€‚

```python
Â  Â  def get_latent_code(self, x):
Â  Â  Â  Â  # Encoder
Â  Â  Â  Â  x1 = self.conv1(x)
Â  Â  Â  Â  x2 = self.conv2(x1)
Â  Â  Â  Â  x3 = self.conv3(x2)
Â  Â  Â  Â  x4 = self.conv4(x3)
Â  Â  Â  Â  x4 = x4.view(x4.size(0), -1)
Â  Â  Â  Â  code = self.fc1(x4)
Â  Â  Â  Â  return code

Â  Â  def generate_img(self, latent_code):
Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  # Decoder
Â  Â  Â  Â  Â  Â  y1 = self.fc2(latent_code)
Â  Â  Â  Â  Â  Â  y1 = y1.view(y1.size(0), 24, 2, 2)
Â  Â  Â  Â  Â  Â  y2 = self.conv5(y1)
Â  Â  Â  Â  Â  Â  y3 = self.conv6(y2)
Â  Â  Â  Â  Â  Â  y4 = self.conv7(y3)
Â  Â  Â  Â  Â  Â  generated_image = self.conv8(y4)
Â  Â  Â  Â  return generated_image
```

æ‰“å°latent_codeåˆ†å¸ƒï¼š
å„ç±»åˆ«çš„åˆ†å¸ƒè¾ƒä¸ºåˆ†æ•£ï¼Œæ•ˆæœå·²ç»æ¯”è¾ƒ`sparse`äº†ï¼Œåç»­çš„æ­£åˆ™åŒ–æˆ–è®¸åªèƒ½ç¨å¾®ä¼˜åŒ–ä¸€ä¸‹æ€§èƒ½ã€‚
![[MSE_MSEL2.png]]

ä»(-5, -5)åˆ°(5, 5)å‡åŒ€é‡‡æ ·æ¢å¤æ•°å­—ï¼Œèƒ½çœ‹åˆ°åœ¨åˆ†ç•Œçš„åœ°æ–¹ä¼šæœ‰é‡‡ç©ºçš„ç°è±¡å‡ºç°ï¼Œæœ‰ä¸€äº›æ— æ„ä¹‰çš„æ•°å­—ç”Ÿæˆï¼Œä½†æ•´ä½“æ¥è¯´æ•ˆæœå·²ç»éå¸¸ä¸é”™äº†ï¼Œå› ä¸ºæˆ‘é‡‡æ ·å°±æ˜¯åœ¨æ¯”è¾ƒä¸­å¿ƒçš„ä½ç½®ç›´æ¥é€‰å–çš„ï¼Œæ‰€ä»¥åªä¼šå‡ºç°åœ¨ä¸€äº›çª„å¸¦ä¸Šçš„æ··æ‚ç°è±¡ï¼Œè€Œä¸ä¼šå‡ºç°å¦‚ä¸‹è¿™ç§è¾ƒæ˜æ˜¾çš„æ— æ„ä¹‰æ•°å­—ï¼š
![[gen_img_4.jpg]]
![[notbad.png]]

---
### 5. åŠ å…¥æ­£åˆ™åŒ–

åŠ å…¥`L2`æ­£åˆ™åŒ–ï¼Œç‰µåˆ¶ä¸€ä¸‹ç‰¹å¾åˆ†å¸ƒå¹¶"é“ºå¼€"latent_codeã€‚

```python
class Trainer:
Â  Â  def __init__(self):
Â  Â  Â  Â  """
Â  Â  Â  Â  initialization...
Â  Â  Â  Â  """
Â  Â  Â  Â  self.opt = torch.optim.Adam(self.net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

Â  Â  def train(self):
Â  Â  Â  Â  """
Â  Â  Â  Â  set dict...
Â  Â  Â  Â  constants setting...
Â  Â  Â  Â  """
Â  Â  Â  Â  for epochs in range(epoch):
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  variations...
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  for i, (x, y) in enumerate(Train_DataLoader):
Â  Â  Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Â  Â  add noise...
Â  Â  Â  Â  Â  Â  Â  Â  process...
Â  Â  Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Â  Â  L2_Reg = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  for param in self.net.parameters():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  L2_Reg += torch.norm(param, 2)
Â  Â  Â  Â  Â  Â  Â  Â  out_img = self.net(img)
Â  Â  Â  Â  Â  Â  Â  Â  loss = self.loss_fn(out_img, img) + WEIGHT_DECAY * L2_Reg
Â  Â  Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Â  Â  backprop...
Â  Â  Â  Â  Â  Â  Â  Â  get latend code...
Â  Â  Â  Â  Â  Â  Â  Â  print states...
Â  Â  Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Save the reconstructed images...
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  """
Â  Â  Â  Â  Save the model...
Â  Â  Â  Â  """

Â  Â  def generate(self):
Â  Â  Â  Â  """
Â  Â  Â  Â  Select an area of the latent space...
Â  Â  Â  Â  Generate images from the selected area...
Â  Â  Â  Â  save images...
Â  Â  Â  Â  """

if __name__ == '__main__':
Â  Â  t = Trainer()
Â  Â  t.train()
Â  Â  t.generate()
```

æ•ˆæœï¼š
å¯ä»¥çœ‹åˆ°ç›¸è¾ƒä¸æœªæ­£åˆ™åŒ–ä¹‹å‰ï¼Œæµ…è‰²éƒ¨åˆ†çš„ç±»åˆ«è¦æ›´åˆ†æ•£ä¸€äº›äº†ï¼Œè€Œä¸æ˜¯èšé›†åœ¨åŒä¸€ä¸ªåŒºåŸŸï¼Œæˆ‘çŒœæµ‹æ­£åˆ™åŒ–ä¹‹åçš„å›¾åƒåˆ†å¸ƒï¼Œæœ‰åœ†åœˆçš„æ•°å­—(å¦‚0, 6, 8, 9)æ•ˆæœä¼šæ›´åŠ åˆ†æ˜ã€‚
![[Latend_Codes 2.png]]

ä»(-5, -5)åˆ°(5, 5)å‡åŒ€é‡‡æ ·æ¢å¤æ•°å­—ï¼Œä¸å°å¿ƒæŠŠåˆ†ç•Œçº¿é‡‡è¿›å»äº†ï¼Œæ–œå¯¹è§’çº¿ä¸Šçš„æ•°å­—æ„ä¹‰éå¸¸ä¸æ˜ç¡®ï¼Œä½†åœ¨åˆ†ç•Œçº¿çš„ä¸¤ä¾§ï¼Œèƒ½éå¸¸æ˜æ˜¾çš„çœ‹åˆ°æ•°å­—çš„ç‰¹å¾å˜åŒ–ï¼Œæ€»ä½“æ¥è¯´æ•ˆæœè¿˜æ˜¯å¾ˆä¸é”™çš„ã€‚
![[generated_images.png]]

---
### # æ¢ç´¢(ä»£ç æ—©æœŸçš„å›°éš¾ä¸å¯¹ç…§è¯•éªŒ)

**bottleneckä¸åŒå¯¼è‡´çš„ç”Ÿæˆæ•ˆæœä¸åŒï¼š**
1. bottleneck = 2
![[gen_img__10.png]]
2. bottleneck = 128
![[gen_img_10.jpg]]

**æŸå¤±å‡½æ•°ä¸åŒå¯¼è‡´çš„ç”Ÿæˆæ•ˆæœä¸åŒï¼š**

_Loss function for binay inputs:_
$l(f(\mathbf{x}))=-\sum_k\left(x_k\log(\widehat{x}_k)+(1-x_k)\log(1-\widehat{x}_k)\right)$

_Loss function for real-valued inputs:_
$l(f(\mathbf{x}))=\frac{1}{2}\sum_k(\widehat{x}_k-x_k)^2$

1. MSE
![[gen_img_9.jpg]]
2. BCE
![[gen_img_10.jpg]]

**æ¿€æ´»å‡½æ•°ï¼š**
1. ReLUåï¼ŒåšBCEä¹‹å‰è¿‡ä¸€ä¸ªSigmoid
![[LC1.png]]
2. å…¨éƒ¨ä½¿ç”¨Sigmoid
![[Latend_Codes 1.png]]

**L2æ­£åˆ™åŒ–ï¼š**
åŠ äº†weight_decayä¹‹åLosså°±æ¢å¤æ­£å¸¸äº†ğŸ¤“
_ä½¿ç”¨MSEæ—¶åŠ å…¥L2æ­£åˆ™åŒ–æ•ˆæœæ­£å¸¸(å›¾ä¸€ä¸ºæ­£åˆ™åŒ–å‰ï¼Œå›¾äºŒä¸ºæ­£åˆ™åŒ–å)ï¼š_
![[MSE_NoL2.png]]
![[MSE_L2.png]]

**ç½‘ç»œç»“æ„ä¸åŒï¼š**
CNNï¼š
æœ€å¼€å§‹å†™çš„å››å±‚CNNåœ¨bottleneckä»128é™è‡³2ä¹‹åå˜å¾—ç¨æœ‰äº›æ¨¡ç³Šï¼Œåœ¨åŠ å…¥å™ªå£°å¹¶é‡‡ç”¨L2æ­£åˆ™åŒ–ä¹‹åæ€§èƒ½éå¸¸å·®åŠ²ï¼Œå¯èƒ½æ˜¯å¤šå±‚ç»“æ„ç¨æœ‰äº›å†—æ‚ï¼Ÿåæ¥ä¿®æ”¹çš„ä¸€ç‰ˆåªæœ‰ä¸¤å±‚ï¼Œæ•ˆæœæœ‰å¾ˆå¥½çš„æå‡ã€‚

MLPï¼š
æ•ˆæœæ¯”CNNè¦å¥½ä¸€äº›

---
## å®éªŒäºŒï¼š All_Dogs AE
### å®éªŒè¦æ±‚ï¼š

- ä»¥MSEä½œä¸ºæŸå¤±å‡½æ•°ï¼Œè®¾ç½®$c$çš„ç»´åº¦ä¸º 8 Ã— 8 Ã— 16ï¼Œæ­å»ºå¹¶è®­ç»ƒæ·±åº¦è‡ªç¼–ç å™¨ç½‘ç»œã€‚
- éšæœºé€‰å–9 å¼ å›¾ç‰‡ï¼Œåˆ†åˆ«å±•ç¤ºæ¯ä¸€å¼ å›¾ç‰‡çš„åŸå›¾å’Œé‡å»ºå›¾åƒï¼Œå¹¶å¯¹latent codeè¿›è¡Œå¯è§†åŒ–ã€‚
- éšæœºé€‰å–256å¼ å›¾ç‰‡ï¼Œé€šè¿‡æ‰€æ„é€ çš„è‡ªç¼–ç å™¨ç½‘ç»œä¸­çš„encoderå¾—åˆ°å…¶å¯¹åº”çš„latent codeã€‚è®¡ç®—è¿™äº› latent codeçš„ç»Ÿè®¡ç‰¹æ€§ï¼Œå¹¶ä»¥æ­¤ä¸ºå‚æ•°æ„é€ é«˜æ–¯åˆ†å¸ƒã€‚è¯•åœ¨ä½ æ‰€å¾—åˆ°çš„é«˜æ–¯åˆ†å¸ƒä¸Šè¿›è¡Œ9 æ¬¡éšæœºé‡‡æ ·ï¼Œå†å°†é‡‡æ ·å¾—åˆ°çš„9ç»„latent codeé€å…¥ decoderï¼Œè§‚å¯Ÿæ‰€å¾—åˆ°çš„å›¾åƒå¹¶æè¿°ä½ è§‚å¯Ÿåˆ°çš„ç°è±¡ã€‚
- åœ¨ä»»åŠ¡(3)çš„åŸºç¡€ä¸Šï¼Œåœ¨è¿™9 å¼ å›¾ç‰‡çš„latent codeä¸Šå åŠ éšæœºçš„é«˜æ–¯å™ªå£°æ‰°åŠ¨ï¼Œè§‚å¯Ÿå åŠ å™ªå£°åçš„latent codeé€å…¥decoderç”Ÿæˆçš„å›¾åƒï¼Œå¹¶è§£é‡Šä½ è§‚å¯Ÿåˆ°çš„ç°è±¡ã€‚
- å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¯·å°†latent codeå åŠ é›¶å‡å€¼é«˜æ–¯å™ªå£°ä½œä¸ºä¸€ç±»æ­£åˆ™è‡ªç¼–ç å™¨æ–¹æ³•ï¼Œç”±æ­¤å¸¦å™ªè®­ç»ƒæ–°çš„æ­£åˆ™è‡ªç¼–ç å™¨ (é™åˆ¶latent code ç»´åº¦ä¸º 8 Ã— 8 Ã— 16)ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸ºäº†ä¿è¯é«˜æ–¯å™ªå£°å…·æœ‰ç¨³å®šçš„æ•ˆæœï¼Œè¿˜éœ€è¦åœ¨**å åŠ å™ªå£°å‰å¯¹latent codeè¿›è¡ŒåŠŸç‡å½’ä¸€åŒ–**ã€‚è¯·åœ¨å™ªå£°æ–¹å·®åˆ†åˆ«ä¸º0.05ï¼Œ0.1ï¼Œ0.15 æ—¶ï¼Œç»™å‡ºDog æ•°æ®é›†ä¸Šé‡å»ºå›¾åƒPSNRçš„å¹³å‡å€¼ï¼Œéœ€è¦å¹¶æ¢ç©¶æ­¤æ—¶ä»latent space é‡‡æ ·æ˜¯å¦æœ‰ç”Ÿæˆæ•ˆæœ
---
### å‰è¨€&èµ„æ–™ï¼š

è¿™æ¬¡æ²¡æ`transform`ç„¶åå›¾ç‰‡`size`ä¹Ÿæ¯”è¾ƒå‹å¥½ï¼Œæ•´å°æ•°æ®é›†å°±æ²¡å¾—å¥½å¤§æ„ä¹‰ã€‚åŒæ—¶ç®€å•çš„ä»£ç ç‰‡æ®µå¹¶æ²¡æœ‰è´´å‡ºå±•ç¤ºï¼Œå®Œæ•´ä»£ç å¯åœ¨é™„ä»¶`All_Dogs_Kaggle.ipynb`ä¸­æŸ¥çœ‹ï¼Œå› ä¸ºåœ¨kaggleä¸Šçš„è¡¥å…¨å’ŒæŠ¥é”™å•¥çš„éƒ½æ¯”è¾ƒçƒ‚ï¼Œæ‰€ä»¥ä»£ç å¯èƒ½æœ‰å†—ä½™éƒ¨åˆ†ï¼Œè¿˜è¯·è§è°…ã€‚

Latent_Codeçš„å¤§å°é€‰æ‹©ï¼š[What is an appropriate size for a latent space of (variational) autoencoders and how it varies with the features of the images?](https://ai.stackexchange.com/questions/37272/what-is-an-appropriate-size-for-a-latent-space-of-variational-autoencoders-and)

_an easy way is to try with different values and look at the likelihood on the test-set log(p)-pick the lowest dimensionality that maximises it. This is a solution in tune with Deep Learning spirit :)
Second solution, maybe a little more grounded, is to decompose your training data with SVD and look at the spectrum of singular values. The number of non trivial (=above some small threshold) values will give you a rough idea of the number of latent dimensions you are going to need._

è§£å†³é‡å»ºæ¨¡ç³Šé—®é¢˜(ä½†æ˜¯VAE)ï¼š[Log Hyperbolic Cosine Loss Improves Variational Auto-Encoder | OpenReview](https://openreview.net/forum?id=rkglvsC9Ym)

---
### 1. ç½‘ç»œæ­å»º

```text
AutoEncoder(
  (encoder): Sequential(
    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))
    (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
  )
  (decoder): Sequential(
    (0): Conv2d(16, 192, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Upsample(scale_factor=2.0, mode='nearest')
    (4): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Upsample(scale_factor=2.0, mode='nearest')
    (8): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Upsample(scale_factor=2.0, mode='nearest')
    (12): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Tanh()
  )
)
```

1. **æ± åŒ–å±‚ï¼š** æœ€å¼€å§‹åœ¨æœªä½¿ç”¨æ± åŒ–å±‚çš„æ—¶å€™ï¼Œå› ä¸ºå¤šå±‚å·ç§¯å±‚å åŠ ï¼Œä¼šå‡ºç°é¢œè‰²ç‰¹å¾æ¶ˆå¤±çš„ç°è±¡ï¼Œå›¾åƒå˜æˆç±»ä¼¼ç°åº¦é£æ ¼çš„å›¾ç‰‡ï¼Œå¯èƒ½æ˜¯æœªå¤„ç†å¥½ç½‘ç»œç»“æ„å¯¼è‡´åœ¨è¿›è¡Œé€šé“å˜æ¢çš„æ—¶å€™å‡ºç°äº†ç‰¹å¾ä¸¢å¤±çš„æƒ…å†µã€‚
2. **æ± åŒ–åå·ç§¯ï¼š** æœ€åä¸€å±‚ä¸ºæ± åŒ–å±‚ï¼Œåœ¨å›¾åƒæ¢å¤åä¼šå‡ºç°ç½‘æ ¼çŠ¶çš„å—æ•ˆåº”ç°è±¡ï¼Œèƒ½çœ‹åˆ°è¾¹ç¼˜æ³›å‡ºRGBçš„è‰²æ™•ï¼Œåœ¨è¿™ä¸€å±‚æ± åŒ–ååŠ å…¥`stride = 1`çš„å·ç§¯å±‚åè¿™ç§ç°è±¡æ¶ˆå¤±ã€‚å¥½åƒè¿˜å¯ä»¥å¯¹å›¾åƒæ‰©å……ä¸€äº›åƒç´ ç„¶åå¯¹æ‰©å……åçš„å›¾åƒè¿›è¡Œå›¾åƒé‡å»ºï¼Œå›¾åƒå—é‡å»ºåå¯¹äºé‡å éƒ¨åˆ†è¿›è¡Œåˆ‡é™¤èˆå¼ƒå¤„ç†ã€‚
3. **ä¸Šé‡‡æ ·ï¼š** å…¶å®`decoder`ä¸­å¤åŸå›¾åƒä½¿ç”¨`upsamlpe`æ•ˆæœè¦æ›´å¥½ï¼Œå› ä¸ºåˆ©ç”¨`Maxpool2d`è¿”å›çš„idxå¯ä»¥æ›´å¥½çš„å¤åŸå›¾åƒï¼Œä½†æ˜¯å› ä¸ºåé¢è¦ä»`latent_code`å†ç”Ÿæˆå›¾åƒï¼Œæ‰€ä»¥å°±ä¸å’‹èƒ½ç”¨äº†ã€‚

---
### 2. æŠ½å–å›¾ç‰‡åé‡å»º

éšæœºç”Ÿæˆ9ä¸ªéšæœºæ•°åæŠ½å–å›¾ç‰‡ï¼Œç»è¿‡`encoder`åå±•ç¤º`latent_code`ï¼Œå†ç»`decoder`è¿›è¡Œé‡å»ºã€‚
æœ€å¼€å§‹æ‰‹ç®—çš„ç½‘ç»œå›¾åƒç»´åº¦ï¼Œæœ€åå‘ç°`latent_code`å¥½åƒå¤§äº†ä¸€å·ï¼Œæ‰çŸ¥é“æŠŠéšè—å±‚ç»´åº¦å¼„æˆ16\*16\*16äº†ï¼ŒæŒ‰è¦æ±‚æ¥å±•ç¤ºçš„è¯ç¡®å®è¦æ¨¡ç³Šä¸€äº›ã€‚

![[Contract.png]]

---
### 3. è®¡ç®—å‚æ•°æ„é€ é«˜æ–¯åˆ†å¸ƒ

![[3e64cbe43ad05f8bdc5b8dcc280ec4f.png]]
VAEé’æ˜¥ç‰ˆï¼Œæ‰‹åŠ¨ç®—ä¸€ä¸ªå‡å€¼å’Œæ–¹å·®å‡ºæ¥è§‚å¯Ÿï¼ŒæŠŠ`Decoder`çš„è¾“å‡ºæ”¹æˆé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®å†æ”¾å›å»å¯¹æ¯”å°±å¯ä»¥å‡çº§ä¸ºVAEäº†ã€‚

è¾“å‡ºç»“æœï¼š
![[Pasted image 20231203120425.png]]

å¯¹æ¯”ç»™å‡ºçš„åˆ†å¸ƒå›¾ï¼š
![[Pasted image 20231203120452.png]]
å¥½åƒæˆ‘è¿™ä¸ªåå·®ä¼šæ›´å¤§ä¸€äº›ï¼Œé‡å¿ƒä¸åœ¨å‡å€¼å¤„ï¼Œéšç©ºé—´çš„åˆ†å¸ƒæƒ…å†µæ¯”è¾ƒæœ‰éšæœºæ€§ã€‚

#### 3.1 éšæœºé‡‡æ ·ç”Ÿæˆçš„9å¼ å›¾ç‰‡

![[Pasted image 20231203121825.png]]
![[Pasted image 20231203121851.png]]
![[Pasted image 20231203121903.png]]

å¯ä»¥æ˜æ˜¾åœ°è§‚å¯Ÿå‡ºåŸºæœ¬ä¸Šéƒ½æ˜¯æ— æ„ä¹‰çš„ç”Ÿæˆå›¾åƒï¼Œå°±åƒMNISTä¸­ç›´æ¥å¯¹éšè—å±‚ç©ºé—´çš„ä¸€ç‰‡åŒºåŸŸé‡‡æ ·ç”Ÿæˆä¸€æ ·ï¼Œç›´æ¥é‡‡æ ·å¾ˆæœ‰å¯èƒ½é‡‡ç©ºï¼Œåœ¨éšç©ºé—´éšæœºä¸€å¤„æ— æ„ä¹‰çš„åœ°ç‚¹ç”Ÿæˆçš„ç‰¹å¾ã€‚
ä¸ºäº†ä½¿ç”Ÿæˆçš„å›¾åƒæ›´çœŸå®ä¸€äº›ï¼Œæˆ‘å‘é‡‡æ ·ç‚¹å¢åŠ äº†ä¸€ä¸ªæƒé‡ï¼Œå»ç‰µåˆ¶å®ƒç”Ÿæˆçš„ä½ç½®ï¼Œåˆ©ç”¨æƒé‡æŠŠé‡‡æ ·ç‚¹å‘çœŸå®å­˜åœ¨çš„æ•°æ®åˆ†å¸ƒä¸Šæ‹‰æ‰¯ã€‚

#### 3.2 éšæœºé‡‡æ ·ç‚¹ç‰µåˆ¶

~~æœ€å¥½çš„å†™æ³•åº”è¯¥æ˜¯åœ¨é‡‡æ ·ç‚¹å‘¨å›´æ‰¾ä¸€ä¸ªç¦»å®ƒæœ€è¿‘çš„çœŸå®æ ·æœ¬ç‚¹å»æ‹Ÿåˆ~~

```python
"""
We can tell from the Generated images that they don't look like dogs.
So we need to add some constraints to the latent code.
Let's make the latent code a bit closer to the real sampled dots.
"""

Delta = 0.25
Generated = []
Generated = np.random.multivariate_normal(Mean, Cov, 9)
Generated = Delta * Generated + (1 - Delta) * encoded_img[0:9]
Generated = Generated.reshape((-1, 16, 8, 8))
print(Generated.shape)
```

![[Pasted image 20231203122510.png]]
![[Pasted image 20231203122516.png]]
![[Pasted image 20231203122521.png]]

è¿™æ ·çœ‹ä¸Šå»å°±èˆ’æœå¤šäº†ï¼Œçˆ±ç‹—äººå£«ğŸ¶æœ‰ç¦äº†ï¼Œè¾¨è®¤éš¾åº¦å¤§å¤§é™ä½ã€‚
ä½†å…¶å®æˆ‘æ„Ÿè§‰è¿™æ ·å¯¹é‡‡æ ·ç‚¹è¿›è¡ŒåŠ æƒï¼Œç›¸æ¯”éšæœºé‡‡æ ·æ¥è¯´ï¼Œæ›´åƒæ˜¯å¯¹å›¾åƒè¿›è¡ŒåŠ å™ªå¤„ç†ï¼Œè½»å¾®åç¦»é‡‡æ ·ç‚¹è€Œå·²ã€‚
é‡æ–°å†™ä¸€ä¸ªä»…åŠ å™ªçš„ç‰ˆæœ¬ï¼Œå‘ç°ç¡®å®æ˜¯è¿™ç§æ„Ÿè§‰ï¼Œä¸è¿‡åŠ å™ªè¦æ›´ä¸è‡ªç„¶ä¸€äº›ï¼Œæ‰€ä»¥è¯´åŠ æƒä¹Ÿè¿˜ç®—åˆç†ï¼Ÿè‡³å°‘çœ‹ä¸Šå»æ›´æ¥è¿‘çœŸå®å›¾ç‰‡ã€‚

```python
# Add Noise to the Generated
Factor = 0.25
Generated = []
Generated = np.random.multivariate_normal(Mean, Cov, 9)
Generated = encoded_img[0:9]
Generated = Generated + Factor * np.random.normal(0, 1, (9, 1024))
Generated = Generated.reshape((-1, 16, 8, 8))
print(Generated.shape)
```

![[Pasted image 20231203123332.png]]
![[Pasted image 20231203123341.png]]
![[Pasted image 20231203123347.png]]

---
### 4. å åŠ å™ªå£°åå†decoder
#### 4.1 å¯¹åŸå§‹éšæœºé‡‡æ ·å›¾ç‰‡åŠ å™ª
![[Pasted image 20231203125125.png]]
![[Pasted image 20231203125829.png]]
![[Pasted image 20231203125838.png]]
#### 4.2 å¯¹åŠ æƒéšæœºé‡‡æ ·å›¾ç‰‡åŠ å™ª
![[Pasted image 20231203130243.png]]
![[Pasted image 20231203130322.png]]
![[Pasted image 20231203130327.png]]

åŠ å…¥å™ªå£°ä¹‹åå¤§è‡´çš„å½¢çŠ¶ç‰¹å¾éƒ½ä¿ç•™ä¸‹æ¥äº†ï¼Œè‰²å½©ç‰¹å¾ä¼šæ”¶åˆ°ä¸€å®šçš„å½±å“ï¼Œä½†æ•´ä½“å½±å“ä¸å¤§ã€‚

---
### 5. åŠ å™ªé‡å»ºæ€§èƒ½

#### 5.1 Standard

éšä¾¿å¯¹ä¸€å¼ å›¾åŠ å™ªåè®¡ç®—PSNRï¼Œè§‚å¯Ÿå›¾ç‰‡åŒºåˆ«ä¸åˆ†è´æ•°ï¼Œæœ‰ä¸ªå¤§æ¦‚çš„è¡¡é‡æ ‡å‡†ã€‚ä¸‹å›¾ç»™å‡ºçš„ç¤ºä¾‹åŸºæœ¬ä¸Šä¸€æ¨¡ä¸€æ ·äº†ï¼Œä½†åªèƒ½è¾¾åˆ°46dBï¼Œæ‰€ä»¥è¯´50å¤šåˆ†è´ç¡®å®æ˜¯æœ‰ç‚¹æ‰¯æ‹äº†ã€‚

```python
idx = np.random.randint(0, len(train_set), 1)
img = Train_Loader.dataset[idx[0]]
img = img.unsqueeze(0).to(device)
print(img.shape)
noise_factor = 0.05
img_slightly_noisy = img + noise_factor * torch.normal(mean=0.0, std=0.1, size=img.size()).to(device)
psnr = CalcuPSNR(img, img_slightly_noisy)
print(psnr)

# show 2 images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(img.cpu().data.squeeze().permute(1, 2, 0))
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(img_slightly_noisy.cpu().data.squeeze().permute(1, 2, 0))
plt.axis('off')
plt.show()
```
```output
torch.Size([1, 3, 64, 64])
[46.07505505]
```
![[Pasted image 20231203132601.png]]
#### 5.2 å®æ“

```python
# Noise
class add_noise(nn.Module):
    def __init__(self, std):
        super(add_noise, self).__init__()
        self.std = std  # std

    # generate Gaussian noise
    def gaussian_noise_layer(self, input_layer, std, noise_factor = 1):
        noise = torch.normal(mean=0.0, std=std, size=input_layer.size()) * noise_factor
        output = input_layer.to(device) + noise.to(device)
        return output

    # Normalize the latent code
    def normalize(self, x):
        pwr = torch.mean(x ** 2)
        out = x / torch.sqrt(pwr)
        return out

    def forward(self, input):
        latent_code = self.normalize(input)
        noisy_code = self.gaussian_noise_layer(latent_code, self.std)
        noisy_code = noisy_code.to(device)
        return noisy_code

# Train
class RealPuppyTrainer:
    def __init__(self, model):
        self.model = model
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
        self.criterion = nn.MSELoss()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.add_noise = add_noise(std=0.05) # std = 0.05/0.1/0.15
```

ä¸ºäº†åæ˜ åˆ°åº•æ˜¯åŠ å™ªå¤„ç†çš„æ€§èƒ½æ•ˆæœä¸å¥½è¿˜æ˜¯AEæœ¬èº«ç”Ÿæˆèƒ½åŠ›çš„ä¸è¶³ï¼Œæˆ‘æŠŠä¸¤ä¸ªPSNRéƒ½ç®—å‡ºæ¥äº†ã€‚
AVG_PSNRæ˜¯å¯¹æ¯”åŸå›¾å’ŒåŠ å™ªç”Ÿæˆå›¾å¾—åˆ°çš„
AVG_noisyPSNRæ˜¯å¯¹æ¯”ç”Ÿæˆå›¾å’ŒåŠ å™ªç”Ÿæˆå›¾å¾—åˆ°çš„

**std = 0.05:** 
```python:
Epoch: 22 | Total loss: 0.369172 | AVG_PSNR: 25.964dB | AVG_noisyPSNR: 42.247dB | Time: 28.19s
Epoch: 23 | Total loss: 0.370368 | AVG_PSNR: 25.727dB | AVG_noisyPSNR: 41.965dB | Time: 27.55s
Epoch: 24 | Total loss: 0.376545 | AVG_PSNR: 25.733dB | AVG_noisyPSNR: 42.165dB | Time: 27.66s
Epoch: 25 | Total loss: 0.357900 | AVG_PSNR: 26.161dB | AVG_noisyPSNR: 41.771dB | Time: 27.71s
Epoch: 26 | Total loss: 0.356455 | AVG_PSNR: 25.992dB | AVG_noisyPSNR: 41.732dB | Time: 28.10s
```
![[Denoising_Epoch_5.png]]
**std = 0.1:** 
```python:
Epoch: 17 | Total loss: 0.372735 | AVG_PSNR: 23.772dB | AVG_noisyPSNR: 37.195dB | Time: 26.22s
Epoch: 18 | Total loss: 0.373087 | AVG_PSNR: 24.039dB | AVG_noisyPSNR: 37.041dB | Time: 26.61s
Epoch: 19 | Total loss: 0.350900 | AVG_PSNR: 24.386dB | AVG_noisyPSNR: 37.146dB | Time: 26.78s
Epoch: 20 | Total loss: 0.368970 | AVG_PSNR: 24.615dB | AVG_noisyPSNR: 36.966dB | Time: 26.55s
Epoch: 21 | Total loss: 0.353576 | AVG_PSNR: 24.865dB | AVG_noisyPSNR: 36.973dB | Time: 26.59s
```
![[Denoising_Epoch_22 (1).png]]
**std = 0.15:** 
```python:
Epoch: 19 | Total loss: 0.368680 | AVG_PSNR: 23.751dB | AVG_noisyPSNR: 35.735dB | Time: 26.10s
Epoch: 20 | Total loss: 0.366096 | AVG_PSNR: 24.094dB | AVG_noisyPSNR: 36.174dB | Time: 27.14s
Epoch: 21 | Total loss: 0.367677 | AVG_PSNR: 24.113dB | AVG_noisyPSNR: 36.138dB | Time: 26.37s
Epoch: 22 | Total loss: 0.363055 | AVG_PSNR: 24.594dB | AVG_noisyPSNR: 35.729dB | Time: 27.35s
Epoch: 23 | Total loss: 0.356284 | AVG_PSNR: 24.462dB | AVG_noisyPSNR: 35.908dB | Time: 26.28s
```
![[Denoising_Epoch_21.png]]

è§‚å¯Ÿå¯ä»¥å¾—å‡ºï¼Œéšç€`std`çš„å¢åŠ ï¼Œ`PSNR`é€æ¸å‡å°ï¼Œä¸»è¦ä½“ç°åœ¨é‡æ„å›¾åƒä¸åŠ å™ªé‡æ„å›¾åƒä¸Šçš„å·®åˆ«ï¼Œè€ŒåŸå›¾å’ŒåŠ å™ªé‡æ„å›¾åƒä¸ŠåŒºåˆ«ä¸ç®—ç‰¹åˆ«å¤§ã€‚
æ€§èƒ½å…¶å®è¿˜ç®—ä¸é”™äº†ï¼ŒåŸºæœ¬ä¸Šæ˜¯æ˜¯å®Œç¾é‡æ„äº†ï¼Œå†æƒ³è¦æå‡åªèƒ½ä¿®æ”¹ç½‘ç»œç»“æ„æˆ–è€…ä¿®æ”¹bottleneckå¤§å°ï¼Œåªèƒ½è¯´éšç©ºé—´ç¡®å®æœ‰ç‚¹éšæœºã€‚

**Cheatç‰ˆæœ¬ï¼Œ16\*16\*16çš„latent_codeï¼š**
é‡å»ºå‡ºæ¥ä¹‹åçœ‹ä¸Šå»å·²ç»éå¸¸ç›¸ä¼¼äº†ï¼Œæ‰€ä»¥è¿™æ ·ä¸€çœ‹å¥½åƒ25å·¦å³çš„PSNRå·²ç»éå¸¸ä¼˜ç§€äº†ï¼Œä¹Ÿæ²¡å¿…è¦å»å—¯å·å‡†ç¡®ç‡äº†ã€‚
![[Denoising_Epoch_29.png]]
```text
...
Epoch: 26 | Total loss: 0.075562 | AVG_PSNR: 31.904dB | Time: 25.48s
Epoch: 27 | Total loss: 0.076207 | AVG_PSNR: 31.163dB | Time: 25.50s
Epoch: 28 | Total loss: 0.071224 | AVG_PSNR: 31.296dB | Time: 26.06s
Epoch: 29 | Total loss: 0.070521 | AVG_PSNR: 32.058dB | Time: 26.14s
Epoch: 30 | Total loss: 0.066973 | AVG_PSNR: 30.472dB | Time: 25.45s
...
```

---
### # å°å‰§åœºï¼š

![[e9fe2dd1d3bd46395e98036c26977bd.png]]
